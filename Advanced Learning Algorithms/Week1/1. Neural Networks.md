### 神经网络的起源与动机
> 神经网络（**Neural networks**）的灵感来自于生物大脑，目的是开发模拟人脑学习和思考方式的软件。
> 尽管神经网络（**Neural networks**）最初受到生物学的启发，现代神经网络与大脑的实际工作方式有很大不同。研究人员今天更多关注工程原理，而不是模仿大脑。

### 神经网络的发展历程
1. **早期发展**：神经网络的研究始于20世纪50年代，但一度失宠。
2. **复兴与衰退**：
   - 1980年代至1990年代早期，神经网络在手写数字识别等领域取得了一定的成功，但在90年代末再次衰退。
3. **深度学习的兴起**：2005年后，神经网络（**Neural networks**）在“深度学习”（**Deep learning**）这一新名词的推动下重新崛起，成为技术热点。深度学习（**Deep learning**）与神经网络几乎是同义词，但“深度学习”更具吸引力。

### 神经网络的应用领域
- **语音识别**：现代神经网络（**Neural networks**）首先在语音识别领域取得显著进展，提升了语音系统的准确性。
- **计算机视觉**：2012年 **ImageNet moment** 标志着计算机视觉领域的重大突破。
- **自然语言处理（NLP）**：近年来，神经网络（**Neural networks**）逐渐应用于文本处理与自然语言处理（**NLP**）领域。
- **其他领域**：如今，神经网络（**Neural networks**）广泛应用于医学成像、气候变化、广告推荐等众多领域。

### 神经元模型与计算
- **生物神经元**：生物神经元接收其他神经元的信号，进行计算后输出给其他神经元。
- **人工神经元**：神经网络（**Neural networks**）使用简化的数学模型来模拟神经元的作用
  - **接收数字输入，进行计算后输出数字结果。多个神经元共同构成复杂的神经网络。**

### 成功的关键因素
- **数据量的增加**：随着互联网和数字化的普及，数据量爆发式增长，神经网络（**Neural networks**）能够利用大量数据来提升模型性能。
  - **传统算法的局限性**：逻辑回归（**Logistic regression**）、线性回归（**Linear regression**）等传统机器学习算法**无法有效扩展以处理海量数据**。
  - **大规模神经网络的优势**：随着数据量的增加和硬件性能的提升，较大的神经网络（**Neural networks**）在语音识别、图像识别、自然语言处理等应用中表现出更好的性能。
- **硬件进步**：**GPU** 的出现大幅提升了神经网络（**Neural networks**）的计算能力，使得训练大规模模型成为可能。
### 未来展望
- 虽然神经网络（**Neural networks**）的**起源受到生物学的启发，但现代研究更关注工程实践和算法优化**。

<img width="293" alt="image" src="https://github.com/user-attachments/assets/418f209e-7380-4265-8b80-3f144ee0e5ee">

- 神经元(Neuron)

<img width="626" alt="image" src="https://github.com/user-attachments/assets/58047334-8c6e-4463-b210-af99c46fde51">
<img width="682" alt="image" src="https://github.com/user-attachments/assets/5b209e6f-667a-4989-a0cb-520d44c50224">
<img width="689" alt="image" src="https://github.com/user-attachments/assets/f64fe4d5-cc9e-49f0-bb10-ea66bdf39052">

> 神经网络（**Neural networks**）通过将多个神经元组合成层次结构，接收输入向量x并生成预测输出。神经网络的强大之处在于其能够**自动学习特征，而不需要人工设计**。通过多个隐藏层，**深度神经网络（Deep Neural Networks, DNNs）** 可以处理更复杂的任务，使其成为现代机器学习中最强大的算法之一。

**神经网络的层级结构**：
   - **输入层（Input layer）**：接收原始输入向量x，如 T 恤的价格、运费、销量等。
   - **隐藏层（Hidden layer）**：处理输入特征并生成中间激活值。每个神经元根据输入向量x进行线性组合，
     之后，通过**激活函数(activation function )** 生成输出a。
   - **输出层（Output layer）**：最终生成预测值，即 T 恤是否成为畅销品的概率。

**神经网络的特点**：
   - **自动特征学习**：神经网络可以自动学习输入特征的组合，而不需要手动构造特征。比如，T恤需求预测模型可以自动学习到负担能力、知名度和感知质量等更具预测性的特征。
   - 神经网络通过反向传播算法**自动调整权w和偏置b**，使得模型的预测更加准确。

**深度神经网络（Deep Neural Networks）**：
   - 当神经网络有多个隐藏层时，它被称为**深度神经网络（Deep Neural Networks, DNNs）。每一层的输出作为下一层的输入，逐步学习更复杂的模式。**
   - 例如，输入层有4个特征x，中间层有3个神经元，最终输出层生成1个预测值。通过这种多层结构，神经网络可以处理更复杂的预测任务。

**架构选择的重要性**：
   - 构建神经网络时，重要的设计决策包括：
     - **隐藏层数量**：有多少层。
     - **每层神经元的数量**：每层有多少个神经元。
   - 这些架构选择会影响模型的表现。深度神经网络通过增加隐藏层数量，能学到更复杂的特征，但也可能导致过拟合等问题。

## E.g. 图像识别
### 神经网络在人脸识别和计算机视觉中的应用总结
> 神经网络 **（Neural Networks）** 在 **计算机视觉（Computer Vision）** 中的工作原理是，通过多层处理从图像中自动提取特征，逐步将像素信息转换为更高级的特征，如边缘、面部部分、最终面部形状。
> 神经网络通过其 **自动学习特征（Feature Learning）** 的能力表现出色，并且可以根据不同的数据集适应不同的任务。

<img width="687" alt="image" src="https://github.com/user-attachments/assets/3e2a1b7d-83bc-4e0b-a12c-3a41488174e3">

1. **人脸识别的应用**：
   - 在构建 **人脸识别（Face Recognition）** 应用时，**神经网络（Neural Networks）** 可以将输入图像（如一张1,000 x 1,000像素的照片）处理为特征向量。该向量包含一百万个像素强度值，每个数字对应图像的一个像素。
   - 神经网络将这些像素值作为输入，并通过多层处理，输出图像中人物的身份。每一层逐步提取图像的特征，最终输出识别结果。

<img width="692" alt="image" src="https://github.com/user-attachments/assets/414e3a89-d409-4223-9707-2e01549eb133">

2. **神经网络层的处理**：
   > **神经网络（Neural Networks）** 的隐藏层可以自行学习如何检测图像中的特征。没有人需要告诉它寻找哪些特征，神经网络能够从数据中自动学习这些特征。
   > **自动特征学习（Feature Learning）**：训练在不同数据集上的神经网络能够自动学习相应的特征。
   - 输入图像首先通过**输入层（Input Layer）**，然后传递到**隐藏层（Hidden Layer）**。每个隐藏层提取不同级别的特征：
     - **第一层**：提取图像中的基础特征，如短的线条或边缘。
        - 第一层的神经元可能会检测到图像中的边缘
     - **第二层**：将这些短边组合，检测面部的一部分，如眼睛、鼻子或耳朵等。
        - 第二层的神经元会将这些边缘组合起来，检测更复杂的面部特征。随着层数增加，神经网络逐渐学习到更高级的特征。
     - **第三层**：聚合面部的各个部分，检测更完整的脸部形状。
   - 最终，**输出层（Output Layer）**根据提取到的脸部特征，估计照片中人物的身份概率。

4. **图像窗口的大小**：
   - 在较低层次，神经元处理的是图像中的小区域（如一小块像素），而在更高层次，神经元会处理更大的图像区域，聚合多个小区域的信息来形成完整的特征。

